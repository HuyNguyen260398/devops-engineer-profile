# ============================================================================
# ArgoCD Helm Values - Base / Production Configuration
# ============================================================================
# Base values for ArgoCD Helm chart, shared across environments.
# - Production (AWS EKS): Referenced by Terraform in inf/terraform/aws-eks/
# - Local testing:        Override with argocd-values-local.yaml
#
# See deploy-argocd-local.sh for local cluster deployment.
# ============================================================================

# Global configuration
global:

  # Security context for all pods
  securityContext:
    runAsNonRoot: true
    runAsUser: 999
    runAsGroup: 999
    fsGroup: 999

  # Network policy
  networkPolicy:
    create: true

  logging:
    format: json
    level: info

# ============================================================================
# ArgoCD Server
# ============================================================================
server:
  replicas: 2

  # Resource management
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # Pod disruption budget for HA
  pdb:
    enabled: true
    minAvailable: 1

  # Autoscaling
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # Security context
  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

  # Ingress configuration (disabled by default, enable for external access)
  ingress:
    enabled: false
    # Uncomment below for AWS ALB Ingress
    # ingressClassName: alb
    # annotations:
    #   alb.ingress.kubernetes.io/scheme: internet-facing
    #   alb.ingress.kubernetes.io/target-type: ip
    #   alb.ingress.kubernetes.io/certificate-arn: "<ACM_CERTIFICATE_ARN>"
    #   alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
    #   alb.ingress.kubernetes.io/ssl-redirect: "443"
    # hosts:
    #   - argocd.your-domain.com
    # tls:
    #   - secretName: argocd-tls
    #     hosts:
    #       - argocd.your-domain.com

  # Metrics for Prometheus
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      namespace: monitoring
      additionalLabels:
        release: kube-prometheus-stack

  # Service type (use LoadBalancer for direct access, ClusterIP + Ingress for production)
  service:
    type: ClusterIP

  # Extra arguments
  extraArgs:
    - --insecure  # TLS terminated at ingress/LB level

# ============================================================================
# ArgoCD Repo Server
# ============================================================================
repoServer:
  replicas: 2

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi

  pdb:
    enabled: true
    minAvailable: 1

  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80

  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      namespace: monitoring
      additionalLabels:
        release: kube-prometheus-stack

# ============================================================================
# ArgoCD Application Controller
# ============================================================================
controller:
  replicas: 1

  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      namespace: monitoring
      additionalLabels:
        release: kube-prometheus-stack

  # Application controller settings
  args:
    appResyncPeriod: "180"           # Sync interval in seconds (3 minutes)
    selfHealTimeout: "5"             # Self-heal timeout in seconds
    repoServerTimeoutSeconds: "120"  # Repo server timeout

# ============================================================================
# ArgoCD ApplicationSet Controller
# ============================================================================
applicationSet:
  enabled: true
  replicas: 2

  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 256Mi

  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      namespace: monitoring
      additionalLabels:
        release: kube-prometheus-stack

# ============================================================================
# ArgoCD Notifications Controller
# ============================================================================
notifications:
  enabled: true

  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 100m
      memory: 128Mi

  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      namespace: monitoring
      additionalLabels:
        release: kube-prometheus-stack

  # Notification templates (Slack example)
  # notifiers:
  #   service.slack: |
  #     token: $slack-token
  # templates:
  #   template.app-sync-succeeded: |
  #     message: |
  #       Application {{.app.metadata.name}} sync succeeded.
  #   template.app-sync-failed: |
  #     message: |
  #       Application {{.app.metadata.name}} sync failed.

# ============================================================================
# Redis (used by ArgoCD for caching)
# ============================================================================
redis:
  enabled: true

  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 256Mi

  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

# Use HA Redis for production
redis-ha:
  enabled: false  # Enable for multi-replica Redis HA setup

# ============================================================================
# Dex (SSO Integration)
# ============================================================================
dex:
  enabled: false  # Enable when SSO is needed, otherwise use ArgoCD built-in auth

# ============================================================================
# ArgoCD ConfigMap
# ============================================================================
configs:
  cm:
    # Application health checks
    resource.customizations: |
      networking.k8s.io/Ingress:
        health.lua: |
          hs = {}
          hs.status = "Healthy"
          return hs

    # RBAC configuration
    admin.enabled: true  # Disable in production after initial setup

    # Kustomize build options
    kustomize.buildOptions: --enable-helm

    # Status badge
    statusbadge.enabled: true

    # Resource tracking method
    application.resourceTrackingMethod: annotation

  # RBAC policies
  rbac:
    policy.default: role:readonly
    policy.csv: |
      p, role:devops, applications, *, */*, allow
      p, role:devops, clusters, get, *, allow
      p, role:devops, repositories, *, *, allow
      p, role:devops, projects, *, *, allow
      p, role:developer, applications, get, */*, allow
      p, role:developer, applications, sync, */*, allow
      p, role:developer, logs, get, */*, allow
      g, devops-team, role:devops
      g, dev-team, role:developer

  # Known hosts for Git SSH
  ssh:
    extraHosts: |
      github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl

  # Repository credentials (managed via Terraform secrets)
  credentialTemplates: {}
  repositories: {}

  params:
    # Server parameters
    server.insecure: true  # TLS terminated at ingress/LB

    # Controller parameters
    controller.status.processors: "20"
    controller.operation.processors: "10"
    controller.self.heal.timeout.seconds: "5"
    controller.repo.server.timeout.seconds: "120"
